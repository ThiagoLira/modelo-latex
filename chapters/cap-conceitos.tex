%% ------------------------------------------------------------------------- %%
\chapter{Conceitos}
\label{cap:conceitos}


\section{Machine Learning}

O campo de Machine Learning (ML) é uma ramo da Ciência da Computação que se arma de métodos estatísticos para criar sistemas que podem aprender (i.e. melhorar sua acurácia) através de dados.

Algoritmos de ML podem ser divididos nas categorias de aprendizado supervisionado, não supervisionado e aprendizado por reforço \citep{dlbook}. Técnicas dos dois primeiros tipos serão usadas para os dados da Intercement.

\subsection{Aprendizado Supervisionado}

Aprendizado Supervisionado consiste a grosso modo em aprender uma distribuição de probabilidade do tipo $p(y | x)$, ou seja, para diversos exemplos de vetores $x$ são fornecidas anotacoes $y$, e desejamos então criar predições de anotacoes $y'$ para novas entradas $x'$. Muitos algoritmos resolvem esse problema por meio da busca pelo conjunto de parânetros $\theta$ que minimizem o erro na família de distribuições $p(y | x,\theta)$.

\subsection{Aprendizado Não Supervisionado}

Para o caso de Aprendizado Não Supervisionado, mantendo a estrutura do exemplo anterior, desejaríamos então modelar uma distribuição do tipo $p(x)$, onde temos também diversos exemplos de vetores aleatórios $x$ e podemos estar estudando alguma propriedade importante dessa distribuição.

\section{Estatística Frequentista e Estatística Bayesiana}

Como nesse trabalho serão usados métodos de inferência Bayesiana aplicados a ML, cabe então uma breve elaboração das diferenças entre os dois grandes \textit{aproacches} da estatística.\\

Digamos que exista um evento aleatório que tenha um resultado com probabilidade $p$ de acontecer. Intuitivamente, se pudessemos repetir infinitas vezes esse evento, a proporção de vezes que esse resultado irá acontecer se aproximará de arbitrariamente de $p$. E então entenderíamos a probailidade $p$ meramente como uma proporção de resultados positivos em uma certa amostra de experimentos. Mas e se o evento não pudesse ser repetido? Quando físicos criam modelos para explicar o nascimento do universo, é impossível pensar em repetir o Big Bang infinitas vezes para que se possam estimar probabilidades de certos eventos cosmologicos acontecerem. Nesse segundo caso, resultados são derivados de \textbf{graus de certeza}, onde a chance de um evento acontecer é estimada pela aplicação de conhecimentos prévios em vista de algo que foi observado posteriormente. A primeira maneira de se entender estatística é chamada de Frequentista e a segunda de Bayesiana. \\

E no campo de ML, as duas maneiras de se gerar predições são estimadores frequentistas e inferência Bayesiana \citep{dlbook}.

\subsection{Estimação por Log-verossimilhança}

Um exemplo de estimação frequentista que será usada nesse trabalho é a de log-verossimilhança. 
Ela segue o princípio de maximizar a verossimilhança dada uma amostra de dados. Ou seja, dada uma matriz de dados $X$ e um conjunto de parâmetros $\theta$, a estimador de máxima verossimilhança de $\theta$ é dado por: \\

\[ \theta = \argmax_{\theta} p_{modelo}(X,\theta) \] 

Onde $p_{modelo}$ busca aproximar a real distribuição geradora dos dados $p$. Assumindo dados i.i.d e trocando a multiplicação por soma de logaritmos temos: \\

\[ \theta = \argmax_{\theta} \sum_{i=1}^{m} \log p_{modelo}(x^{(i)},\theta) \]


\subsection{Inferência Bayesiana em Machine Learning}

O tratamento Bayesiano para modelos de ML é bastante diverso dos frequentistas. Em uma análise frequentista estima-se um valor de $\theta$ e então todas as predições são feitas a partir desse valor. No caso Baysiano se consideram todos os possíveis valores de $\theta$ ao se fazer uma predição. É preciso especificar um grau de certeza \textbf{anterior} $p(\theta)$ sobre os parâmetros, e então consideramos que os dados \textbf{foram observados} e usamos a lei de Bayes para calcular a \textbf{probabilidade} posterior $p(\theta | X,Y)$ usando para tal $p(X,Y | \theta)$, a chamada verossimilhança. 

\[    p(\theta | X,Y) = \frac{p(Y| X,\theta) p(\theta)}{p(X)}   \]

Finalmente, para realizar uma inferência devemos integrar por toda a distribuição $p(\theta)$ marginalizando esse parâmetro. Se por exemplo queremos uma nova anotação $y^*$ para um novo dado $x^*$:

\[ p(y^* | x^* , X,Y) = \int  p(y^* | x^*,\theta) p(\theta | X,Y)  d\theta \]

Essa integral é geralmente intratável \citep{bayesml}, e portanto será usado uma técnica que aproxima uma inferência Bayesiana em redes neurais, o MC Dropout \citep{dropbayes}.

%% ------------------------------------------------------------------------- %%
\section{Escolha de Modelos}

\subsection{Temporalidade dos Dados}

Pela análise realizada na sessão anterior, podemos concluir que os dados não possuem nenhuma sazonalidade. O problema a ser resolvido para a modelagem desses dados é um problema de aprendizado supervisionado de regressão, e como explicado no início desse documento, devemos fornecer exemplos de entrada e saida para que possivelmente algum modelo aprenda um conjunto de fatores $\theta$ que consigam gerar com alguma acurária novas predições. É importante então sabermos que tipo de informação é útil para darmos como entrada para o modelo. No exemplo da predição de consumo de energia elétrica sabemos que é util para o modelo, além da entrada, ele também receber a \textbf{data} da mesma, pois como foi explicado, esses dados possuem sazonalidade anual. Para os dados de cimento já chegamos a conclusão que a data de uma medida é irrelevante. Porém não descartamos a possibilidade de medidas próximas temporalmente influenciarem uma mesma saída.

Em um problema simples de aprendizado supervisionado gostariamos de aprender uma função $f$ tal que para um par inédito de dados $x^*,y^*$, a nossa função dependa apenas de $x^*$ para que se gere uma predição. Para os dados em questão pode ser que um valor i.e. índice de dureza dependa não só da última entrada, mas de diversas entradas anteriores. 

Ou seja, nossos dados podem ter sido gerados por uma distribuição de probabilidade da forma $p(y | x_{t} ,x_{t -1},x_{t -2},x_{t-3} , \dots, x_{t-T})$, onde uma saida $y$ é condicionada pelas últimas T entradas. Para resolver um problema de aprendizado dessa natureza, devemos usar \textbf{modelos sequenciais}. 

Iremos então experimentar com modelos sequenciais e não-sequencias para testar a acurária de ambos no problema em questão.



\subsection{Inferência Bayesiana}

Será experimentado um modelo sequencial e um modelo não-sequencial que se armem de avanços recentes na área de Machine Learning para que os mesmos possam calcular probabilidades posteriores usando a lei de Bayes. Tais modelos usam uma filosofia diferente para o cálculo de suas predições, estas não sendo mais fruto de maximizar uma verossimilhança ou uma estimativa pontual (achar um conjunto de parâmetros $\theta$ que minimizem alguma métrica de erro). As chamadas Redes Neurais Bayesianas consideram seus parâmetros como distribuições de probabilidade, o que torna cada predição uma ação estocástica, permitindo que sejam calculadas variâncias para cada predição, podendo assim o engenheiro de dados calcular a incerteza do problema.

Uma maneira de implementar uma Rede Neural Bayesiana é usar a técnica Monte Carlo Dropout. Dessa maneira aproximando uma rede neural comum a um processo estocástico sem muitas mudanças no seu código. Usaremos o MC Dropout em uma rede neural clássica (não-sequencial) e em uma RNN (sequencial) para ver como o calculo dessa incerteza auxilia no domínio do problema.

\subsection{Modelo Sequencial}
Com o sucesso de modelos sequenciais no campo do Deep Learning, iremos averiguar se é possível modelar sequencialmente os dados da produção de cimento usando dois desses modelos. 
\\

\subsection{Rede Neural Recorrente}
% \input{tiks/RNNSimplified.tex}

Como podemos ver na imagem, a entrada $x$, ao lado do estado interno $W$, são usados para gerar uma predição. Essa por sua vez é comparada com o nosso dado real para que se calcule um erro. O estado $W$ é calculado em cada iteração e usado no cálculo da próxima predição. De modo que esse estado é capaz de transmitir temporalmente ao longo do treinamento informações de dados anteriores.
\\

Essa classe de modelos normalmente é usada para modelagem de linguagem. Buscando estimar uma distribuição de probabilidade $p(w_t | w_{t-1},w_{t-2},w_{t-3} \dots ) $ onde os $w_i$ são palavras subsequentes de um texto. Normalmente um modelo dessa natureza busca resolver um problema de classifição, onde a próxima palavra a ser prevista pelo modelo é uma entre todas as possibilidades de um certo vocabulário. No caso do domínio em questão desejamamos resolver um problema de regressão, onde nosso alvo é um valor numérico. Para treinar um desses modelos, precisamos usar como entrada exemplos subsequentes de dados, onde cada exemplo de entrada tem um exemplo pareado de saída. Basicamente redes neurais recorrentes funcionam recebendo um exemplo de entrada, criando uma representação interna com o mesmo e então gerando uma saída e comparando essa saída com o exemplo de saída real, gerando um erro. Finalmente, esse erro é propagado para alterar seus parâmetros (com o fim de achar um conjunto de parâmetros que gere boas previsões). Podemos vizualizar esse modelo também ao longo do tempo na imagem a seguir:


% \input{tiks/RRNSimplifiedUnrolled.tex}


Essa imagem mostra exatamente o mesmo modelo da imagem anterior, porém, agora visualizamos o modelo a cada iteração temporal. O estado W é usado como entrada juntamente com o proximo $x_i$ para uma nova iteração.

\bigskip

Como já explicado anteriormente, nossos dados de entrada e saída não estão necessariamente pareados perfeitamente dia a dia. Portanto, foi necessário achar intervalos de tempo nos dados onde existe esse pareamento. Isso reduz drasticamente quais períodos representados nos dados realmente podem ser usados para treinar um desses modelos.


\section{Outros Modelos} 

\subsubsection{Redes Neurais}


Redes neurais são aproximadores universais de funções. Se tivermos um problema
de classificação onde queremos aprender uma função da forma $y = f^*(x)$, uma
Rede Neural define um mapeamento $y = f(x ; \theta)$, onde $\theta$ é o vetor de
parâmetros que serão aprendidos com o fim de minimizar o erro do aproximador.

O modelo é uma composição de transformações lineares e não-lineares da forma: \\

\[ f(x)=  \sigma(W*x + b) \]

Onde sigma é alguma função não-linear como a função sigmóide. A computação da
saída de uma rede neural então pode ser escrita como:

\[   y = f_n \circ f_{n-1} \dots f_1(x)  \]

Para uma rede neural de $n$ \textbf{camadas}. Onde cada camada será uma função
$f_i$ cujos parâmetros são $W$ e $b$.

\[ f_i (x)=  a_i = \sigma(W_i*a_{i-1} + b_i) \]





É interessante notar que uma rede neural é equivalente a realizar uma regressão logística por neurônio. Sendo que uma rede neural com apenas um neurônio é uma regressão logística dos dados. A seguir está reproduzida uma rede neural simples com uma camada oculta e dois neurônios de saída.


%\input{tiks/NN.tex}


Na imagem mostramos como seria uma rede que usa como parâmetros alguns dos dados de Farinha para modelar os índices RC3 e RC7 dos dados de expedição.

\bigskip
\subsubsection{Regressão Linear}
Os modelos são também comparados com uma regressão linear. Que usa estimação por mínimos quadrados para calcular um peso para cada parâmetro de entrada. De modo que a soma ponderada por esses pesos possa aproximar nosso alvo.


\subsubsection{Random Forest}

Random Forests são um método de \textbf{Ensemble Learning} para classificação ou regressão. \textbf{Ensemble Learning} é uma família de técnicas no qual diversos modelos "fracos" são usados em conjunto com algum sistema de votação para que a a acurária do sistema em conjunto se torne melhor que a de qualquer um dos modelos sozinho. Seguindo essa ideia, Random Forests são conjuntos de diveras árvores de decisão simples unidas por um meta-algoritmo de votação para que se produza uma predição muito mais eficaz.




%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../quali"
%%% End: